{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/chenyuheng/PTI/')\n",
    "import dnnlib\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt ... done\n"
     ]
    }
   ],
   "source": [
    "url = 'https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/metrics/vgg16.pt'\n",
    "with dnnlib.util.open_url(url) as f:\n",
    "    # \n",
    "    vgg16 = torch.jit.load(f).eval().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.jit._script.RecursiveScriptModule"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vgg16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class VGG16(Module):\n",
      "  __parameters__ = [\"img_mean\", \"img_std\", \"lpips0\", \"lpips1\", \"lpips2\", \"lpips3\", \"lpips4\", ]\n",
      "  __buffers__ = []\n",
      "  img_mean : Tensor\n",
      "  img_std : Tensor\n",
      "  lpips0 : Tensor\n",
      "  lpips1 : Tensor\n",
      "  lpips2 : Tensor\n",
      "  lpips3 : Tensor\n",
      "  lpips4 : Tensor\n",
      "  training : bool\n",
      "  layers : __torch__.torch.nn.modules.container.ModuleDict\n",
      "  def forward(self: __torch__.VGG16,\n",
      "    img: Tensor,\n",
      "    resize_images: bool=True,\n",
      "    return_features: bool=False,\n",
      "    return_lpips: bool=False,\n",
      "    use_fp16: bool=False) -> Tensor:\n",
      "    _0 = __torch__.torch.nn.functional.affine_grid\n",
      "    _1 = __torch__.torch.nn.functional.grid_sample\n",
      "    _2 = __torch__.torch.functional.___torch_mangle_2.norm\n",
      "    _3 = uninitialized(Tensor)\n",
      "    batch_size, channels, height, width, = torch.size(img)\n",
      "    if torch.eq(channels, 3):\n",
      "      pass\n",
      "    else:\n",
      "      ops.prim.RaiseException(\"AssertionError: \")\n",
      "    if resize_images:\n",
      "      _4 = True\n",
      "    else:\n",
      "      _4 = return_lpips\n",
      "    if _4:\n",
      "      pass\n",
      "    else:\n",
      "      ops.prim.RaiseException(\"AssertionError: \")\n",
      "    if return_features:\n",
      "      _5 = return_lpips\n",
      "    else:\n",
      "      _5 = False\n",
      "    if torch.__not__(_5):\n",
      "      pass\n",
      "    else:\n",
      "      ops.prim.RaiseException(\"AssertionError: \")\n",
      "    if use_fp16:\n",
      "      _6 = 5\n",
      "    else:\n",
      "      _6 = 6\n",
      "    x = torch.to(img, _6)\n",
      "    if resize_images:\n",
      "      theta = torch.eye(2, 3, dtype=None, layout=None, device=ops.prim.device(x))\n",
      "      _7 = torch.select(torch.select(theta, 0, 0), 0, 2)\n",
      "      _8 = torch.select(torch.select(theta, 0, 0), 0, 0)\n",
      "      _9 = torch.div(_8, width)\n",
      "      _10 = torch.select(torch.select(theta, 0, 0), 0, 0)\n",
      "      _11 = torch.sub(_9, torch.div(_10, 224))\n",
      "      _12 = torch.add_(_7, _11)\n",
      "      _13 = torch.select(torch.select(theta, 0, 1), 0, 2)\n",
      "      _14 = torch.select(torch.select(theta, 0, 1), 0, 1)\n",
      "      _15 = torch.div(_14, height)\n",
      "      _16 = torch.select(torch.select(theta, 0, 1), 0, 1)\n",
      "      _17 = torch.sub(_15, torch.div(_16, 224))\n",
      "      _18 = torch.add_(_13, _17)\n",
      "      _19 = torch.to(theta, ops.prim.dtype(x))\n",
      "      theta0 = torch.repeat(torch.unsqueeze(_19, 0), [batch_size, 1, 1])\n",
      "      grid = _0(theta0, [batch_size, channels, 224, 224], False, )\n",
      "      x1 = _1(x, grid, \"bilinear\", \"border\", False, )\n",
      "      x0 = x1\n",
      "    else:\n",
      "      x0 = x\n",
      "    x2 = torch.div_(x0, 255)\n",
      "    img_mean = self.img_mean\n",
      "    x3 = torch.sub_(x2, img_mean)\n",
      "    img_std = self.img_std\n",
      "    x4 = torch.div_(x3, img_std)\n",
      "    if return_lpips:\n",
      "      ys = annotate(List[Tensor], [])\n",
      "      layers = self.layers\n",
      "      conv1 = layers.conv1\n",
      "      conv2 = layers.conv2\n",
      "      pool1 = layers.pool1\n",
      "      conv3 = layers.conv3\n",
      "      conv4 = layers.conv4\n",
      "      pool2 = layers.pool2\n",
      "      conv5 = layers.conv5\n",
      "      conv6 = layers.conv6\n",
      "      conv7 = layers.conv7\n",
      "      pool3 = layers.pool3\n",
      "      conv8 = layers.conv8\n",
      "      conv9 = layers.conv9\n",
      "      conv10 = layers.conv10\n",
      "      pool4 = layers.pool4\n",
      "      conv11 = layers.conv11\n",
      "      conv12 = layers.conv12\n",
      "      conv13 = layers.conv13\n",
      "      pool5 = layers.pool5\n",
      "      fc1 = layers.fc1\n",
      "      fc2 = layers.fc2\n",
      "      fc3 = layers.fc3\n",
      "      softmax = layers.softmax\n",
      "      _21 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_21, \"conv1\"):\n",
      "        _22 = torch.append(ys, torch.to(x4, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _23 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _24 = torch.__not__(torch.__contains__(_23, \"conv1\"))\n",
      "      if _24:\n",
      "        x5 = (conv1).forward(x4, )\n",
      "      else:\n",
      "        x5 = x4\n",
      "      _25 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_25, \"conv2\"):\n",
      "        _26 = torch.append(ys, torch.to(x5, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _27 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _28 = torch.__not__(torch.__contains__(_27, \"conv2\"))\n",
      "      if _28:\n",
      "        x6 = (conv2).forward(x5, )\n",
      "      else:\n",
      "        x6 = x5\n",
      "      _29 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_29, \"pool1\"):\n",
      "        _30 = torch.append(ys, torch.to(x6, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _31 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _32 = torch.__not__(torch.__contains__(_31, \"pool1\"))\n",
      "      if _32:\n",
      "        x7 = (pool1).forward(x6, )\n",
      "      else:\n",
      "        x7 = x6\n",
      "      _33 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_33, \"conv3\"):\n",
      "        _34 = torch.append(ys, torch.to(x7, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _35 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _36 = torch.__not__(torch.__contains__(_35, \"conv3\"))\n",
      "      if _36:\n",
      "        x8 = (conv3).forward(x7, )\n",
      "      else:\n",
      "        x8 = x7\n",
      "      _37 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_37, \"conv4\"):\n",
      "        _38 = torch.append(ys, torch.to(x8, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _39 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _40 = torch.__not__(torch.__contains__(_39, \"conv4\"))\n",
      "      if _40:\n",
      "        x9 = (conv4).forward(x8, )\n",
      "      else:\n",
      "        x9 = x8\n",
      "      _41 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_41, \"pool2\"):\n",
      "        _42 = torch.append(ys, torch.to(x9, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _43 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _44 = torch.__not__(torch.__contains__(_43, \"pool2\"))\n",
      "      if _44:\n",
      "        x10 = (pool2).forward(x9, )\n",
      "      else:\n",
      "        x10 = x9\n",
      "      _45 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_45, \"conv5\"):\n",
      "        _46 = torch.append(ys, torch.to(x10, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _47 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _48 = torch.__not__(torch.__contains__(_47, \"conv5\"))\n",
      "      if _48:\n",
      "        x11 = (conv5).forward(x10, )\n",
      "      else:\n",
      "        x11 = x10\n",
      "      _49 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_49, \"conv6\"):\n",
      "        _50 = torch.append(ys, torch.to(x11, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _51 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _52 = torch.__not__(torch.__contains__(_51, \"conv6\"))\n",
      "      if _52:\n",
      "        x12 = (conv6).forward(x11, )\n",
      "      else:\n",
      "        x12 = x11\n",
      "      _53 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_53, \"conv7\"):\n",
      "        _54 = torch.append(ys, torch.to(x12, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _55 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _56 = torch.__not__(torch.__contains__(_55, \"conv7\"))\n",
      "      if _56:\n",
      "        x13 = (conv7).forward(x12, )\n",
      "      else:\n",
      "        x13 = x12\n",
      "      _57 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_57, \"pool3\"):\n",
      "        _58 = torch.append(ys, torch.to(x13, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _59 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _60 = torch.__not__(torch.__contains__(_59, \"pool3\"))\n",
      "      if _60:\n",
      "        x14 = (pool3).forward(x13, )\n",
      "      else:\n",
      "        x14 = x13\n",
      "      _61 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_61, \"conv8\"):\n",
      "        _62 = torch.append(ys, torch.to(x14, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _63 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _64 = torch.__not__(torch.__contains__(_63, \"conv8\"))\n",
      "      if _64:\n",
      "        x15 = (conv8).forward(x14, )\n",
      "      else:\n",
      "        x15 = x14\n",
      "      _65 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_65, \"conv9\"):\n",
      "        _66 = torch.append(ys, torch.to(x15, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _67 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _68 = torch.__not__(torch.__contains__(_67, \"conv9\"))\n",
      "      if _68:\n",
      "        x16 = (conv9).forward(x15, )\n",
      "      else:\n",
      "        x16 = x15\n",
      "      _69 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_69, \"conv10\"):\n",
      "        _70 = torch.append(ys, torch.to(x16, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _71 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _72 = torch.__not__(torch.__contains__(_71, \"conv10\"))\n",
      "      if _72:\n",
      "        x17 = (conv10).forward(x16, )\n",
      "      else:\n",
      "        x17 = x16\n",
      "      _73 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_73, \"pool4\"):\n",
      "        _74 = torch.append(ys, torch.to(x17, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _75 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _76 = torch.__not__(torch.__contains__(_75, \"pool4\"))\n",
      "      if _76:\n",
      "        x18 = (pool4).forward(x17, )\n",
      "      else:\n",
      "        x18 = x17\n",
      "      _77 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_77, \"conv11\"):\n",
      "        _78 = torch.append(ys, torch.to(x18, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _79 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _80 = torch.__not__(torch.__contains__(_79, \"conv11\"))\n",
      "      if _80:\n",
      "        x19 = (conv11).forward(x18, )\n",
      "      else:\n",
      "        x19 = x18\n",
      "      _81 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_81, \"conv12\"):\n",
      "        _82 = torch.append(ys, torch.to(x19, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _83 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _84 = torch.__not__(torch.__contains__(_83, \"conv12\"))\n",
      "      if _84:\n",
      "        x20 = (conv12).forward(x19, )\n",
      "      else:\n",
      "        x20 = x19\n",
      "      _85 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_85, \"conv13\"):\n",
      "        _86 = torch.append(ys, torch.to(x20, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _87 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _88 = torch.__not__(torch.__contains__(_87, \"conv13\"))\n",
      "      if _88:\n",
      "        x21 = (conv13).forward(x20, )\n",
      "      else:\n",
      "        x21 = x20\n",
      "      _89 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_89, \"pool5\"):\n",
      "        _90 = torch.append(ys, torch.to(x21, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _91 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _92 = torch.__not__(torch.__contains__(_91, \"pool5\"))\n",
      "      if _92:\n",
      "        x22 = (pool5).forward(x21, )\n",
      "      else:\n",
      "        x22 = x21\n",
      "      _93 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_93, \"fc1\"):\n",
      "        _94 = torch.append(ys, torch.to(x22, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _95 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _96 = torch.__not__(torch.__contains__(_95, \"fc1\"))\n",
      "      if _96:\n",
      "        x23 = (fc1).forward(x22, )\n",
      "      else:\n",
      "        x23 = x22\n",
      "      _97 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_97, \"fc2\"):\n",
      "        _98 = torch.append(ys, torch.to(x23, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _99 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _100 = torch.__not__(torch.__contains__(_99, \"fc2\"))\n",
      "      if _100:\n",
      "        x24 = (fc2).forward(x23, )\n",
      "      else:\n",
      "        x24 = x23\n",
      "      _101 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      if torch.__contains__(_101, \"fc3\"):\n",
      "        _102 = torch.append(ys, torch.to(x24, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _103 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _104 = torch.__not__(torch.__contains__(_103, \"fc3\"))\n",
      "      if _104:\n",
      "        x25 = (fc3).forward(x24, )\n",
      "      else:\n",
      "        x25 = x24\n",
      "      _105 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
      "      _106 = torch.__contains__(_105, \"softmax\")\n",
      "      if _106:\n",
      "        _107 = torch.append(ys, torch.to(x25, 6))\n",
      "      else:\n",
      "        pass\n",
      "      _108 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
      "      _109 = torch.__contains__(_108, \"softmax\")\n",
      "      if torch.__not__(_109):\n",
      "        x26 = (softmax).forward(x25, )\n",
      "      else:\n",
      "        pass\n",
      "      lpips0 = self.lpips0\n",
      "      lpips1 = self.lpips1\n",
      "      lpips2 = self.lpips2\n",
      "      lpips3 = self.lpips3\n",
      "      lpips4 = self.lpips4\n",
      "      _110 = [lpips0, lpips1, lpips2, lpips3, lpips4]\n",
      "      _111 = [9223372036854775807, torch.len(ys), torch.len(_110)]\n",
      "      for idx in range(ops.prim.min(_111)):\n",
      "        y = ys[idx]\n",
      "        w = _110[idx]\n",
      "        _112 = _2(y, \"fro\", 1, True, None, None, )\n",
      "        y0 = torch.div(y, torch.add(_112, 1e-10))\n",
      "        _113 = torch.div(w, (torch.size(y0))[2])\n",
      "        _114 = torch.div(_113, (torch.size(y0))[3])\n",
      "        y1 = torch.mul(y0, torch.sqrt(_114))\n",
      "        _115 = torch._set_item(ys, idx, torch.flatten(y1, 1))\n",
      "      _20 = torch.cat(ys, 1)\n",
      "    else:\n",
      "      layers0 = self.layers\n",
      "      conv14 = layers0.conv1\n",
      "      conv20 = layers0.conv2\n",
      "      pool10 = layers0.pool1\n",
      "      conv30 = layers0.conv3\n",
      "      conv40 = layers0.conv4\n",
      "      pool20 = layers0.pool2\n",
      "      conv50 = layers0.conv5\n",
      "      conv60 = layers0.conv6\n",
      "      conv70 = layers0.conv7\n",
      "      pool30 = layers0.pool3\n",
      "      conv80 = layers0.conv8\n",
      "      conv90 = layers0.conv9\n",
      "      conv105 = layers0.conv10\n",
      "      pool40 = layers0.pool4\n",
      "      conv111 = layers0.conv11\n",
      "      conv121 = layers0.conv12\n",
      "      conv131 = layers0.conv13\n",
      "      pool50 = layers0.pool5\n",
      "      fc10 = layers0.fc1\n",
      "      fc20 = layers0.fc2\n",
      "      fc30 = layers0.fc3\n",
      "      softmax0 = layers0.softmax\n",
      "      x27 = (conv14).forward(x4, )\n",
      "      x28 = (conv20).forward(x27, )\n",
      "      x29 = (pool10).forward(x28, )\n",
      "      x30 = (conv30).forward(x29, )\n",
      "      x31 = (conv40).forward(x30, )\n",
      "      x32 = (pool20).forward(x31, )\n",
      "      x33 = (conv50).forward(x32, )\n",
      "      x34 = (conv60).forward(x33, )\n",
      "      x35 = (conv70).forward(x34, )\n",
      "      x36 = (pool30).forward(x35, )\n",
      "      x37 = (conv80).forward(x36, )\n",
      "      x38 = (conv90).forward(x37, )\n",
      "      x39 = (conv105).forward(x38, )\n",
      "      x40 = (pool40).forward(x39, )\n",
      "      x41 = (conv111).forward(x40, )\n",
      "      x42 = (conv121).forward(x41, )\n",
      "      x43 = (conv131).forward(x42, )\n",
      "      x44 = (pool50).forward(x43, )\n",
      "      x45 = (fc10).forward(x44, )\n",
      "      x46 = (fc20).forward(x45, )\n",
      "      x47 = torch.to(x46, 6)\n",
      "      if return_features:\n",
      "        _116, _117 = True, x47\n",
      "      else:\n",
      "        _116, _117 = False, _3\n",
      "      if _116:\n",
      "        _118 = _117\n",
      "      else:\n",
      "        x48 = (fc30).forward(x47, )\n",
      "        _118 = (softmax0).forward(x48, )\n",
      "      _20 = _118\n",
      "    return _20\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(vgg16._c.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG16(Module):\n",
    "  __parameters__ = [\"img_mean\", \"img_std\", \"lpips0\", \"lpips1\", \"lpips2\", \"lpips3\", \"lpips4\", ]\n",
    "  __buffers__ = []\n",
    "  img_mean : Tensor\n",
    "  img_std : Tensor\n",
    "  lpips0 : Tensor\n",
    "  lpips1 : Tensor\n",
    "  lpips2 : Tensor\n",
    "  lpips3 : Tensor\n",
    "  lpips4 : Tensor\n",
    "  training : bool\n",
    "  layers : __torch__.torch.nn.modules.container.ModuleDict\n",
    "  def forward(self: __torch__.VGG16,\n",
    "    img: Tensor,\n",
    "    resize_images: bool=True,\n",
    "    return_features: bool=False,\n",
    "    return_lpips: bool=False,\n",
    "    use_fp16: bool=False) -> Tensor:\n",
    "    _0 = __torch__.torch.nn.functional.affine_grid\n",
    "    _1 = __torch__.torch.nn.functional.grid_sample\n",
    "    _2 = __torch__.torch.functional.___torch_mangle_2.norm\n",
    "    _3 = uninitialized(Tensor)\n",
    "    batch_size, channels, height, width, = torch.size(img)\n",
    "    if torch.eq(channels, 3):\n",
    "      pass\n",
    "    else:\n",
    "      ops.prim.RaiseException(\"AssertionError: \")\n",
    "    if resize_images:\n",
    "      _4 = True\n",
    "    else:\n",
    "      _4 = return_lpips\n",
    "    if _4:\n",
    "      pass\n",
    "    else:\n",
    "      ops.prim.RaiseException(\"AssertionError: \")\n",
    "    if return_features:\n",
    "      _5 = return_lpips\n",
    "    else:\n",
    "      _5 = False\n",
    "    if torch.__not__(_5):\n",
    "      pass\n",
    "    else:\n",
    "      ops.prim.RaiseException(\"AssertionError: \")\n",
    "    if use_fp16:\n",
    "      _6 = 5\n",
    "    else:\n",
    "      _6 = 6\n",
    "    x = torch.to(img, _6)\n",
    "    if resize_images:\n",
    "      theta = torch.eye(2, 3, dtype=None, layout=None, device=ops.prim.device(x))\n",
    "      _7 = torch.select(torch.select(theta, 0, 0), 0, 2)\n",
    "      _8 = torch.select(torch.select(theta, 0, 0), 0, 0)\n",
    "      _9 = torch.div(_8, width)\n",
    "      _10 = torch.select(torch.select(theta, 0, 0), 0, 0)\n",
    "      _11 = torch.sub(_9, torch.div(_10, 224))\n",
    "      _12 = torch.add_(_7, _11)\n",
    "      _13 = torch.select(torch.select(theta, 0, 1), 0, 2)\n",
    "      _14 = torch.select(torch.select(theta, 0, 1), 0, 1)\n",
    "      _15 = torch.div(_14, height)\n",
    "      _16 = torch.select(torch.select(theta, 0, 1), 0, 1)\n",
    "      _17 = torch.sub(_15, torch.div(_16, 224))\n",
    "      _18 = torch.add_(_13, _17)\n",
    "      _19 = torch.to(theta, ops.prim.dtype(x))\n",
    "      theta0 = torch.repeat(torch.unsqueeze(_19, 0), [batch_size, 1, 1])\n",
    "      grid = _0(theta0, [batch_size, channels, 224, 224], False, )\n",
    "      x1 = _1(x, grid, \"bilinear\", \"border\", False, )\n",
    "      x0 = x1\n",
    "    else:\n",
    "      x0 = x\n",
    "    x2 = torch.div_(x0, 255)\n",
    "    img_mean = self.img_mean\n",
    "    x3 = torch.sub_(x2, img_mean)\n",
    "    img_std = self.img_std\n",
    "    x4 = torch.div_(x3, img_std)\n",
    "    if return_lpips:\n",
    "      ys = annotate(List[Tensor], [])\n",
    "      layers = self.layers\n",
    "      conv1 = layers.conv1\n",
    "      conv2 = layers.conv2\n",
    "      pool1 = layers.pool1\n",
    "      conv3 = layers.conv3\n",
    "      conv4 = layers.conv4\n",
    "      pool2 = layers.pool2\n",
    "      conv5 = layers.conv5\n",
    "      conv6 = layers.conv6\n",
    "      conv7 = layers.conv7\n",
    "      pool3 = layers.pool3\n",
    "      conv8 = layers.conv8\n",
    "      conv9 = layers.conv9\n",
    "      conv10 = layers.conv10\n",
    "      pool4 = layers.pool4\n",
    "      conv11 = layers.conv11\n",
    "      conv12 = layers.conv12\n",
    "      conv13 = layers.conv13\n",
    "      pool5 = layers.pool5\n",
    "      fc1 = layers.fc1\n",
    "      fc2 = layers.fc2\n",
    "      fc3 = layers.fc3\n",
    "      softmax = layers.softmax\n",
    "      _21 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_21, \"conv1\"):\n",
    "        _22 = torch.append(ys, torch.to(x4, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _23 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _24 = torch.__not__(torch.__contains__(_23, \"conv1\"))\n",
    "      if _24:\n",
    "        x5 = (conv1).forward(x4, )\n",
    "      else:\n",
    "        x5 = x4\n",
    "      _25 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_25, \"conv2\"):\n",
    "        _26 = torch.append(ys, torch.to(x5, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _27 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _28 = torch.__not__(torch.__contains__(_27, \"conv2\"))\n",
    "      if _28:\n",
    "        x6 = (conv2).forward(x5, )\n",
    "      else:\n",
    "        x6 = x5\n",
    "      _29 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_29, \"pool1\"):\n",
    "        _30 = torch.append(ys, torch.to(x6, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _31 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _32 = torch.__not__(torch.__contains__(_31, \"pool1\"))\n",
    "      if _32:\n",
    "        x7 = (pool1).forward(x6, )\n",
    "      else:\n",
    "        x7 = x6\n",
    "      _33 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_33, \"conv3\"):\n",
    "        _34 = torch.append(ys, torch.to(x7, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _35 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _36 = torch.__not__(torch.__contains__(_35, \"conv3\"))\n",
    "      if _36:\n",
    "        x8 = (conv3).forward(x7, )\n",
    "      else:\n",
    "        x8 = x7\n",
    "      _37 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_37, \"conv4\"):\n",
    "        _38 = torch.append(ys, torch.to(x8, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _39 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _40 = torch.__not__(torch.__contains__(_39, \"conv4\"))\n",
    "      if _40:\n",
    "        x9 = (conv4).forward(x8, )\n",
    "      else:\n",
    "        x9 = x8\n",
    "      _41 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_41, \"pool2\"):\n",
    "        _42 = torch.append(ys, torch.to(x9, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _43 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _44 = torch.__not__(torch.__contains__(_43, \"pool2\"))\n",
    "      if _44:\n",
    "        x10 = (pool2).forward(x9, )\n",
    "      else:\n",
    "        x10 = x9\n",
    "      _45 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_45, \"conv5\"):\n",
    "        _46 = torch.append(ys, torch.to(x10, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _47 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _48 = torch.__not__(torch.__contains__(_47, \"conv5\"))\n",
    "      if _48:\n",
    "        x11 = (conv5).forward(x10, )\n",
    "      else:\n",
    "        x11 = x10\n",
    "      _49 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_49, \"conv6\"):\n",
    "        _50 = torch.append(ys, torch.to(x11, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _51 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _52 = torch.__not__(torch.__contains__(_51, \"conv6\"))\n",
    "      if _52:\n",
    "        x12 = (conv6).forward(x11, )\n",
    "      else:\n",
    "        x12 = x11\n",
    "      _53 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_53, \"conv7\"):\n",
    "        _54 = torch.append(ys, torch.to(x12, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _55 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _56 = torch.__not__(torch.__contains__(_55, \"conv7\"))\n",
    "      if _56:\n",
    "        x13 = (conv7).forward(x12, )\n",
    "      else:\n",
    "        x13 = x12\n",
    "      _57 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_57, \"pool3\"):\n",
    "        _58 = torch.append(ys, torch.to(x13, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _59 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _60 = torch.__not__(torch.__contains__(_59, \"pool3\"))\n",
    "      if _60:\n",
    "        x14 = (pool3).forward(x13, )\n",
    "      else:\n",
    "        x14 = x13\n",
    "      _61 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_61, \"conv8\"):\n",
    "        _62 = torch.append(ys, torch.to(x14, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _63 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _64 = torch.__not__(torch.__contains__(_63, \"conv8\"))\n",
    "      if _64:\n",
    "        x15 = (conv8).forward(x14, )\n",
    "      else:\n",
    "        x15 = x14\n",
    "      _65 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_65, \"conv9\"):\n",
    "        _66 = torch.append(ys, torch.to(x15, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _67 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _68 = torch.__not__(torch.__contains__(_67, \"conv9\"))\n",
    "      if _68:\n",
    "        x16 = (conv9).forward(x15, )\n",
    "      else:\n",
    "        x16 = x15\n",
    "      _69 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_69, \"conv10\"):\n",
    "        _70 = torch.append(ys, torch.to(x16, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _71 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _72 = torch.__not__(torch.__contains__(_71, \"conv10\"))\n",
    "      if _72:\n",
    "        x17 = (conv10).forward(x16, )\n",
    "      else:\n",
    "        x17 = x16\n",
    "      _73 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_73, \"pool4\"):\n",
    "        _74 = torch.append(ys, torch.to(x17, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _75 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _76 = torch.__not__(torch.__contains__(_75, \"pool4\"))\n",
    "      if _76:\n",
    "        x18 = (pool4).forward(x17, )\n",
    "      else:\n",
    "        x18 = x17\n",
    "      _77 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_77, \"conv11\"):\n",
    "        _78 = torch.append(ys, torch.to(x18, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _79 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _80 = torch.__not__(torch.__contains__(_79, \"conv11\"))\n",
    "      if _80:\n",
    "        x19 = (conv11).forward(x18, )\n",
    "      else:\n",
    "        x19 = x18\n",
    "      _81 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_81, \"conv12\"):\n",
    "        _82 = torch.append(ys, torch.to(x19, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _83 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _84 = torch.__not__(torch.__contains__(_83, \"conv12\"))\n",
    "      if _84:\n",
    "        x20 = (conv12).forward(x19, )\n",
    "      else:\n",
    "        x20 = x19\n",
    "      _85 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_85, \"conv13\"):\n",
    "        _86 = torch.append(ys, torch.to(x20, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _87 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _88 = torch.__not__(torch.__contains__(_87, \"conv13\"))\n",
    "      if _88:\n",
    "        x21 = (conv13).forward(x20, )\n",
    "      else:\n",
    "        x21 = x20\n",
    "      _89 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_89, \"pool5\"):\n",
    "        _90 = torch.append(ys, torch.to(x21, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _91 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _92 = torch.__not__(torch.__contains__(_91, \"pool5\"))\n",
    "      if _92:\n",
    "        x22 = (pool5).forward(x21, )\n",
    "      else:\n",
    "        x22 = x21\n",
    "      _93 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_93, \"fc1\"):\n",
    "        _94 = torch.append(ys, torch.to(x22, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _95 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _96 = torch.__not__(torch.__contains__(_95, \"fc1\"))\n",
    "      if _96:\n",
    "        x23 = (fc1).forward(x22, )\n",
    "      else:\n",
    "        x23 = x22\n",
    "      _97 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_97, \"fc2\"):\n",
    "        _98 = torch.append(ys, torch.to(x23, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _99 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _100 = torch.__not__(torch.__contains__(_99, \"fc2\"))\n",
    "      if _100:\n",
    "        x24 = (fc2).forward(x23, )\n",
    "      else:\n",
    "        x24 = x23\n",
    "      _101 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      if torch.__contains__(_101, \"fc3\"):\n",
    "        _102 = torch.append(ys, torch.to(x24, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _103 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _104 = torch.__not__(torch.__contains__(_103, \"fc3\"))\n",
    "      if _104:\n",
    "        x25 = (fc3).forward(x24, )\n",
    "      else:\n",
    "        x25 = x24\n",
    "      _105 = [\"pool1\", \"pool2\", \"pool3\", \"pool4\", \"pool5\"]\n",
    "      _106 = torch.__contains__(_105, \"softmax\")\n",
    "      if _106:\n",
    "        _107 = torch.append(ys, torch.to(x25, 6))\n",
    "      else:\n",
    "        pass\n",
    "      _108 = [\"pool5\", \"fc1\", \"fc2\", \"fc3\", \"softmax\"]\n",
    "      _109 = torch.__contains__(_108, \"softmax\")\n",
    "      if torch.__not__(_109):\n",
    "        x26 = (softmax).forward(x25, )\n",
    "      else:\n",
    "        pass\n",
    "      lpips0 = self.lpips0\n",
    "      lpips1 = self.lpips1\n",
    "      lpips2 = self.lpips2\n",
    "      lpips3 = self.lpips3\n",
    "      lpips4 = self.lpips4\n",
    "      _110 = [lpips0, lpips1, lpips2, lpips3, lpips4]\n",
    "      _111 = [9223372036854775807, torch.len(ys), torch.len(_110)]\n",
    "      for idx in range(ops.prim.min(_111)):\n",
    "        y = ys[idx]\n",
    "        w = _110[idx]\n",
    "        _112 = _2(y, \"fro\", 1, True, None, None, )\n",
    "        y0 = torch.div(y, torch.add(_112, 1e-10))\n",
    "        _113 = torch.div(w, (torch.size(y0))[2])\n",
    "        _114 = torch.div(_113, (torch.size(y0))[3])\n",
    "        y1 = torch.mul(y0, torch.sqrt(_114))\n",
    "        _115 = torch._set_item(ys, idx, torch.flatten(y1, 1))\n",
    "      _20 = torch.cat(ys, 1)\n",
    "    else:\n",
    "      layers0 = self.layers\n",
    "      conv14 = layers0.conv1\n",
    "      conv20 = layers0.conv2\n",
    "      pool10 = layers0.pool1\n",
    "      conv30 = layers0.conv3\n",
    "      conv40 = layers0.conv4\n",
    "      pool20 = layers0.pool2\n",
    "      conv50 = layers0.conv5\n",
    "      conv60 = layers0.conv6\n",
    "      conv70 = layers0.conv7\n",
    "      pool30 = layers0.pool3\n",
    "      conv80 = layers0.conv8\n",
    "      conv90 = layers0.conv9\n",
    "      conv105 = layers0.conv10\n",
    "      pool40 = layers0.pool4\n",
    "      conv111 = layers0.conv11\n",
    "      conv121 = layers0.conv12\n",
    "      conv131 = layers0.conv13\n",
    "      pool50 = layers0.pool5\n",
    "      fc10 = layers0.fc1\n",
    "      fc20 = layers0.fc2\n",
    "      fc30 = layers0.fc3\n",
    "      softmax0 = layers0.softmax\n",
    "      x27 = (conv14).forward(x4, )\n",
    "      x28 = (conv20).forward(x27, )\n",
    "      x29 = (pool10).forward(x28, )\n",
    "      x30 = (conv30).forward(x29, )\n",
    "      x31 = (conv40).forward(x30, )\n",
    "      x32 = (pool20).forward(x31, )\n",
    "      x33 = (conv50).forward(x32, )\n",
    "      x34 = (conv60).forward(x33, )\n",
    "      x35 = (conv70).forward(x34, )\n",
    "      x36 = (pool30).forward(x35, )\n",
    "      x37 = (conv80).forward(x36, )\n",
    "      x38 = (conv90).forward(x37, )\n",
    "      x39 = (conv105).forward(x38, )\n",
    "      x40 = (pool40).forward(x39, )\n",
    "      x41 = (conv111).forward(x40, )\n",
    "      x42 = (conv121).forward(x41, )\n",
    "      x43 = (conv131).forward(x42, )\n",
    "      x44 = (pool50).forward(x43, )\n",
    "      x45 = (fc10).forward(x44, )\n",
    "      x46 = (fc20).forward(x45, )\n",
    "      x47 = torch.to(x46, 6)\n",
    "      if return_features:\n",
    "        _116, _117 = True, x47\n",
    "      else:\n",
    "        _116, _117 = False, _3\n",
    "      if _116:\n",
    "        _118 = _117\n",
    "      else:\n",
    "        x48 = (fc30).forward(x47, )\n",
    "        _118 = (softmax0).forward(x48, )\n",
    "      _20 = _118\n",
    "    return _20\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VGG16(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(VGG16, self).__init__()\n",
    "        self.img_mean = torch.tensor([0.485, 0.456, 0.406]).view(1, 3, 1, 1)\n",
    "        self.img_std = torch.tensor([0.229, 0.224, 0.225]).view(1, 3, 1, 1)\n",
    "        # Define VGG16 layers using nn.Sequential or ModuleDict\n",
    "        self.layers = nn.ModuleDict({\n",
    "            \"conv1\": nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            \"conv2\": nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            \"pool1\": nn.MaxPool2d(2),\n",
    "            # Add all other layers following the VGG16 architecture\n",
    "            \"conv3\": nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            \"conv4\": nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
    "            \"pool2\": nn.MaxPool2d(2),\n",
    "            # ...\n",
    "        })\n",
    "    \n",
    "    def forward(self, img, resize_images=True, return_features=False, return_lpips=False, use_fp16=False):\n",
    "        batch_size, channels, height, width = img.size()\n",
    "        assert channels == 3, \"Input image must have 3 channels\"\n",
    "\n",
    "        if resize_images:\n",
    "            theta = torch.eye(2, 3).unsqueeze(0).repeat(batch_size, 1, 1).to(img.device)\n",
    "            grid = F.affine_grid(theta, [batch_size, 3, 224, 224], align_corners=False)\n",
    "            img = F.grid_sample(img, grid, mode='bilinear', padding_mode='border')\n",
    "\n",
    "        img = img / 255.0\n",
    "        img = (img - self.img_mean.to(img.device)) / self.img_std.to(img.device)\n",
    "\n",
    "        if use_fp16:\n",
    "            img = img.half()\n",
    "\n",
    "        ys = []\n",
    "        x = img\n",
    "        for name in [\"conv1\", \"conv2\", \"pool1\", \"conv3\", \"conv4\", \"pool2\"]:  # Add layers as needed\n",
    "            x = self.layers[name](x)\n",
    "            if return_lpips and name.startswith(\"pool\"):\n",
    "                ys.append(x)\n",
    "\n",
    "        if return_features:\n",
    "            return ys if return_lpips else x\n",
    "        return x"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
